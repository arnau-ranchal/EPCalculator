<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>EPCalculator Documentation - Mathematical Background</title>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <style>
    :root {
      --primary-color: #C8102E;
      --text-color: #222;
      --bg-color: #fff;
      --code-bg: #f5f5f5;
      --border-color: #e0e0e0;
    }

    * {
      box-sizing: border-box;
    }

    body {
      font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, sans-serif;
      line-height: 1.7;
      color: var(--text-color);
      background: var(--bg-color);
      margin: 0;
      padding: 0;
    }

    .container {
      max-width: 900px;
      margin: 0 auto;
      padding: 40px 24px;
    }

    header {
      background: linear-gradient(135deg, var(--primary-color), #8B0000);
      color: white;
      padding: 60px 24px;
      text-align: center;
    }

    header h1 {
      margin: 0 0 16px 0;
      font-size: 2.5rem;
      font-weight: 700;
    }

    header p {
      margin: 0;
      opacity: 0.9;
      font-size: 1.1rem;
    }

    .back-link {
      display: inline-block;
      margin-bottom: 24px;
      color: var(--primary-color);
      text-decoration: none;
      font-weight: 500;
    }

    .back-link:hover {
      text-decoration: underline;
    }

    h2 {
      color: var(--primary-color);
      border-bottom: 2px solid var(--primary-color);
      padding-bottom: 8px;
      margin-top: 48px;
    }

    h3 {
      color: #444;
      margin-top: 32px;
    }

    .definition-box {
      background: #fef2f2;
      border-left: 4px solid var(--primary-color);
      padding: 20px 24px;
      margin: 24px 0;
      border-radius: 0 8px 8px 0;
    }

    .definition-box h4 {
      margin: 0 0 12px 0;
      color: var(--primary-color);
    }

    .info-box {
      background: #f0f7ff;
      border-left: 4px solid #1976D2;
      padding: 20px 24px;
      margin: 24px 0;
      border-radius: 0 8px 8px 0;
    }

    .info-box h4 {
      margin: 0 0 12px 0;
      color: #1976D2;
    }

    code {
      background: var(--code-bg);
      padding: 2px 6px;
      border-radius: 4px;
      font-family: 'Fira Code', 'Consolas', monospace;
      font-size: 0.9em;
    }

    pre {
      background: var(--code-bg);
      padding: 16px;
      border-radius: 8px;
      overflow-x: auto;
    }

    pre code {
      background: none;
      padding: 0;
    }

    .equation {
      background: #fafafa;
      padding: 20px;
      border-radius: 8px;
      margin: 20px 0;
      text-align: center;
      overflow-x: auto;
    }

    table {
      width: 100%;
      border-collapse: collapse;
      margin: 24px 0;
    }

    th, td {
      border: 1px solid var(--border-color);
      padding: 12px;
      text-align: left;
    }

    th {
      background: #f5f5f5;
      font-weight: 600;
    }

    .toc {
      background: #f9f9f9;
      padding: 24px;
      border-radius: 8px;
      margin: 24px 0;
    }

    .toc h3 {
      margin-top: 0;
    }

    .toc ul {
      margin: 0;
      padding-left: 24px;
    }

    .toc li {
      margin: 8px 0;
    }

    .toc a {
      color: var(--primary-color);
      text-decoration: none;
    }

    .toc a:hover {
      text-decoration: underline;
    }

    footer {
      text-align: center;
      padding: 40px;
      color: #666;
      border-top: 1px solid var(--border-color);
      margin-top: 60px;
    }

    @media (max-width: 600px) {
      header h1 {
        font-size: 1.8rem;
      }

      .container {
        padding: 24px 16px;
      }
    }
  </style>
</head>
<body>
  <header>
    <h1>EPCalculator Documentation</h1>
    <p>Mathematical Background for Error Probability Computation</p>
  </header>

  <div class="container">
    <a href="/" class="back-link">&larr; Back to EPCalculator</a>

    <nav class="toc">
      <h3>Table of Contents</h3>
      <ul>
        <li><a href="#introduction">1. Introduction to Error Exponents</a></li>
        <li><a href="#gallager">2. The Gallager Random Coding Bound</a></li>
        <li><a href="#e0-function">3. The E&#8320; Function</a></li>
        <li><a href="#computation">4. Numerical Computation</a>
          <ul>
            <li><a href="#computation">4.1 Gauss-Hermite Quadrature</a></li>
            <li><a href="#computation">4.2 Change of Variables</a></li>
            <li><a href="#computation">4.3 Matrix Formulation</a></li>
            <li><a href="#computation">4.4 E&#8320; Computation Formula</a></li>
            <li><a href="#computation">4.5 Gradient Computation</a></li>
            <li><a href="#computation">4.6 Log-Space Computation</a></li>
            <li><a href="#computation">4.7 Optimization Algorithm</a></li>
          </ul>
        </li>
        <li><a href="#quantities">5. Related Quantities</a></li>
        <li><a href="#references">6. References</a></li>
      </ul>
    </nav>

    <section id="introduction">
      <h2>1. Introduction to Error Exponents</h2>

      <p>
        In digital communication systems, we are interested in the probability that transmitted
        information is received incorrectly. For a code of length \(n\), the <strong>error probability</strong>
        \(P_e\) typically decays exponentially with the code length:
      </p>

      <div class="equation">
        \[ P_e \approx 2^{-nE(R)} \]
      </div>

      <p>
        where \(R\) is the code rate (bits per channel use) and \(E(R)\) is the <strong>error exponent</strong>
        (also called reliability function). The error exponent quantifies how fast the error probability
        decreases as we increase the code length.
      </p>

      <div class="definition-box">
        <h4>Key Insight</h4>
        <p>
          A positive error exponent \(E(R) > 0\) means reliable communication is possible at rate \(R\).
          The larger the exponent, the faster errors decrease with code length, and the shorter the
          code needed for a target error rate.
        </p>
      </div>
    </section>

    <section id="gallager">
      <h2>2. The Gallager Random Coding Bound</h2>

      <p>
        The <strong>Gallager random coding bound</strong> provides a lower bound on the error exponent
        achievable by random codes. For a discrete-input continuous-output channel (like AWGN with
        discrete modulation), the random coding error exponent is:
      </p>

      <div class="equation">
        \[ E_r(R) = \max_{0 \leq \rho \leq 1} \left[ E_0(\rho) - \rho R \right] \]
      </div>

      <p>
        where \(E_0(\rho)\) is the <strong>Gallager function</strong>, a key quantity that depends on:
      </p>

      <ul>
        <li>The constellation (modulation scheme)</li>
        <li>The input distribution \(Q(x)\)</li>
        <li>The channel (SNR for AWGN)</li>
        <li>The parameter \(\rho \in [0, 1]\)</li>
      </ul>

      <div class="info-box">
        <h4>Optimization over &rho;</h4>
        <p>
          The parameter \(\rho\) acts as a trade-off parameter. EPCalculator finds the optimal
          \(\rho^*\) that maximizes the error exponent for each given rate \(R\). This optimization
          is performed numerically using gradient descent.
        </p>
      </div>
    </section>

    <section id="e0-function">
      <h2>3. The E&#8320; Function</h2>

      <h3>3.1 Definition</h3>

      <p>
        For a discrete constellation \(\mathcal{X} = \{x_1, x_2, \ldots, x_M\}\) with input distribution
        \(Q(x)\) and AWGN channel with noise variance \(N_0/2\) per dimension, the Gallager function is:
      </p>

      <div class="equation">
        \[ E_0(\rho) = -\log_2 \int_{-\infty}^{\infty} \left[ \sum_{x \in \mathcal{X}} Q(x) \, p(y|x)^{\frac{1}{1+\rho}} \right]^{1+\rho} dy \]
      </div>

      <p>where \(p(y|x)\) is the channel transition probability:</p>

      <div class="equation">
        \[ p(y|x) = \frac{1}{\sqrt{\pi N_0}} \exp\left( -\frac{|y-x|^2}{N_0} \right) \]
      </div>

      <h3>3.2 Properties of E&#8320;</h3>

      <table>
        <tr>
          <th>Property</th>
          <th>Description</th>
        </tr>
        <tr>
          <td>\(E_0(0) = 0\)</td>
          <td>At \(\rho = 0\), the function equals zero</td>
        </tr>
        <tr>
          <td>\(E_0(\rho) \geq 0\)</td>
          <td>Always non-negative</td>
        </tr>
        <tr>
          <td>Concave in \(\rho\)</td>
          <td>The function is concave, enabling efficient optimization</td>
        </tr>
        <tr>
          <td>\(E_0(1) = R_0\)</td>
          <td>At \(\rho = 1\), equals the cutoff rate</td>
        </tr>
        <tr>
          <td>\(\lim_{\rho \to 0} E'_0(\rho) = I(X;Y)\)</td>
          <td>Derivative at 0 relates to mutual information</td>
        </tr>
      </table>

      <h3>3.3 For 2D Constellations (PSK, QAM)</h3>

      <p>
        For two-dimensional constellations, the integral becomes a double integral over both
        real and imaginary components of the received signal:
      </p>

      <div class="equation">
        \[ E_0(\rho) = -\log_2 \iint \left[ \sum_{x \in \mathcal{X}} Q(x) \, p(y|x)^{\frac{1}{1+\rho}} \right]^{1+\rho} dy_I \, dy_Q \]
      </div>
    </section>

    <section id="computation">
      <h2>4. Numerical Computation</h2>

      <h3>4.1 Gauss-Hermite Quadrature</h3>

      <p>
        The integrals in \(E_0\) involve Gaussian-weighted functions. For 2D constellations (PSK, QAM),
        the AWGN channel output \(y = x + n\) where \(n \sim \mathcal{CN}(0, N_0)\). The key insight is that
        the channel transition probability has a Gaussian form:
      </p>

      <div class="equation">
        \[ p(y|x) = \frac{1}{\pi N_0} \exp\left( -\frac{|y-x|^2}{N_0} \right) \]
      </div>

      <p>
        <strong>Gauss-Hermite quadrature</strong> approximates integrals of the form:
      </p>

      <div class="equation">
        \[ \int_{-\infty}^{\infty} f(t) e^{-t^2} dt \approx \sum_{k=1}^{N} w_k f(t_k) \]
      </div>

      <p>
        where \(t_k\) are the roots of the Hermite polynomial \(H_N(t)\) and \(w_k\) are the
        corresponding weights. EPCalculator uses \(N = 15-20\) quadrature points.
      </p>

      <h3>4.2 Change of Variables</h3>

      <p>
        To apply Gauss-Hermite quadrature, we perform a change of variables. The received signal is:
      </p>

      <div class="equation">
        \[ y = \sqrt{\text{SNR}} \cdot x + z, \quad z = z_I + j z_Q \]
      </div>

      <p>
        where \(z_I, z_Q \sim \mathcal{N}(0, 1/2)\) are independent real Gaussians.
        With the substitution \(z_I = t_I\) and \(z_Q = t_Q\), the 2D integral becomes:
      </p>

      <div class="equation">
        \[ \iint f(y) \, p(z) \, dz_I \, dz_Q = \frac{1}{\pi} \iint f(\sqrt{\text{SNR}} \cdot x + t_I + jt_Q) \, e^{-(t_I^2 + t_Q^2)} \, dt_I \, dt_Q \]
      </div>

      <p>
        This is approximated by a double sum over quadrature nodes:
      </p>

      <div class="equation">
        \[ \approx \frac{1}{\pi} \sum_{k=1}^{N} \sum_{\ell=1}^{N} w_k w_\ell \, f\left(\sqrt{\text{SNR}} \cdot x + t_k + j t_\ell\right) \]
      </div>

      <h3>4.3 Matrix Formulation</h3>

      <p>
        EPCalculator uses an efficient <strong>matrix-based approach</strong> with the Eigen C++ library.
        We define the following matrices:
      </p>

      <div class="definition-box">
        <h4>Matrix Definitions</h4>
        <p><strong>Input Distribution Vector \(\mathbf{Q}\)</strong> (size \(M \times 1\)):</p>
        <div class="equation">
          \[ Q_i = Q(x_i), \quad i = 1, \ldots, M \]
        </div>

        <p><strong>Quadrature Points Vector \(\mathbf{y}\)</strong> (size \(M \cdot N^2 \times 1\)):</p>
        <p>For each constellation point \(x_i\) and each quadrature pair \((t_k, t_\ell)\):</p>
        <div class="equation">
          \[ y_{i,k,\ell} = \sqrt{\text{SNR}} \cdot x_i + t_k + j t_\ell \]
        </div>

        <p><strong>Distance Matrix \(\mathbf{D}\)</strong> (size \(M \times M \cdot N^2\)):</p>
        <div class="equation">
          \[ D_{i,j} = \left| y_j - \sqrt{\text{SNR}} \cdot x_i \right|^2 \]
        </div>
        <p>This stores the squared Euclidean distance from each quadrature point \(y_j\) to each
        scaled constellation point \(\sqrt{\text{SNR}} \cdot x_i\).</p>

        <p><strong>Weight Matrix \(\mathbf{\Pi}\)</strong> (size \(M \times M \cdot N^2\)):</p>
        <div class="equation">
          \[ \Pi_{i,(i,k,\ell)} = w_k \cdot w_\ell, \quad \Pi_{i,j} = 0 \text{ otherwise} \]
        </div>
        <p>This is a sparse matrix encoding the quadrature weights, associating each symbol \(x_i\)
        with its corresponding quadrature points.</p>
      </div>

      <h3>4.4 E&#8320; Computation Formula</h3>

      <p>
        Using the matrix notation, \(E_0(\rho)\) is computed as:
      </p>

      <div class="equation">
        \[ E_0(\rho) = -\log_2\left( \frac{1}{\pi} \cdot \mathbf{Q}^T \cdot \left( \mathbf{\Pi} \odot e^{\frac{\rho}{1+\rho} \mathbf{D}} \right) \cdot \left( \mathbf{Q}^T \cdot e^{-\frac{1}{1+\rho} \mathbf{D}} \right)^\rho \right) \]
      </div>

      <p>
        where \(\odot\) denotes element-wise multiplication and the exponentials are applied element-wise.
        More explicitly, define:
      </p>

      <div class="equation">
        \[ g_j = \sum_{i=1}^{M} Q_i \cdot \exp\left( -\frac{D_{i,j}}{1+\rho} \right) \]
      </div>

      <div class="equation">
        \[ E_0(\rho) = -\log_2\left( \frac{1}{\pi} \sum_{i=1}^{M} Q_i \sum_{k,\ell} w_k w_\ell \cdot \exp\left( \frac{\rho \cdot D_{i,(i,k,\ell)}}{1+\rho} \right) \cdot g_{(i,k,\ell)}^\rho \right) \]
      </div>

      <h3>4.5 Gradient Computation</h3>

      <p>
        The optimization over \(\rho\) requires the derivative \(\frac{\partial E_0}{\partial \rho}\).
        Let \(s = \frac{1}{1+\rho}\), then:
      </p>

      <div class="equation">
        \[ \frac{\partial E_0}{\partial \rho} = -\frac{1}{\ln 2} \cdot \frac{F'(\rho)}{F(\rho)} \]
      </div>

      <p>where \(F(\rho)\) is the argument of the logarithm in \(E_0\). The derivative involves:</p>

      <div class="equation">
        \[ \frac{\partial}{\partial \rho}\left[ g_j^\rho \right] = g_j^\rho \left( \ln g_j + \rho \cdot \frac{g'_j}{g_j} \right) \]
      </div>

      <p>The full analytical gradient is computed in C++ using Eigen matrix operations for efficiency.</p>

      <h3>4.6 Log-Space Computation</h3>

      <p>
        At high SNR, the exponential terms can cause numerical overflow (values exceed \(10^{308}\)).
        EPCalculator detects this and switches to <strong>log-space arithmetic</strong>:
      </p>

      <div class="equation">
        \[ \log \sum_i e^{a_i} = \max_i(a_i) + \log \sum_i e^{a_i - \max_i(a_i)} \]
      </div>

      <p>
        All intermediate computations are performed in log-space, and the final result is
        converted back. This ensures stability across the full SNR range (0 to 100+ dB).
      </p>

      <h3>4.7 Optimization Algorithm</h3>

      <p>
        The optimal \(\rho^*\) is found via <strong>gradient descent</strong> on the concave objective:
      </p>

      <div class="equation">
        \[ \max_{0 \leq \rho \leq 1} \left[ E_0(\rho) - \rho R \right] \]
      </div>

      <p>
        The gradient of the objective is \(\frac{\partial E_0}{\partial \rho} - R\).
        Convergence is typically achieved in 10-50 iterations with a threshold of \(10^{-6}\).
        The concavity of \(E_0(\rho)\) guarantees a unique global maximum.
      </p>

      <div class="info-box">
        <h4>Implementation Note</h4>
        <p>
          EPCalculator uses the Eigen C++ library for efficient matrix operations. The computation
          is vectorized, allowing simultaneous evaluation of all \(M \cdot N^2\) terms. For a
          16-QAM constellation with \(N=20\) quadrature points, this involves matrices of size
          \(16 \times 6400\), computed in milliseconds on modern hardware.
        </p>
      </div>
    </section>

    <section id="quantities">
      <h2>5. Related Quantities</h2>

      <h3>5.1 Cutoff Rate (R&#8320;)</h3>

      <p>
        The <strong>cutoff rate</strong> is defined as \(R_0 = E_0(1)\). It represents the rate
        above which sequential decoding becomes impractical. For a discrete constellation:
      </p>

      <div class="equation">
        \[ R_0 = -\log_2 \left[ \sum_{i,j} Q(x_i) Q(x_j) \exp\left( -\frac{|x_i - x_j|^2}{4N_0} \right) \right] \]
      </div>

      <div class="definition-box">
        <h4>Interpretation</h4>
        <p>
          The cutoff rate provides a computationally-motivated threshold: below \(R_0\),
          the error exponent is positive and decoding complexity is manageable. Above \(R_0\),
          exponentially complex decoders may be required.
        </p>
      </div>

      <h3>5.2 Mutual Information I(X;Y)</h3>

      <p>
        The <strong>mutual information</strong> \(I(X;Y)\) is the maximum rate at which information
        can be reliably transmitted (the channel capacity for the given input distribution):
      </p>

      <div class="equation">
        \[ I(X;Y) = \sum_{x \in \mathcal{X}} Q(x) \int p(y|x) \log_2 \frac{p(y|x)}{\sum_{x'} Q(x') p(y|x')} dy \]
      </div>

      <p>
        For rates \(R < I(X;Y)\), reliable communication is possible (Shannon's theorem).
        For rates \(R < R_0 < I(X;Y)\), random coding achieves positive error exponents.
      </p>

      <h3>5.3 Relationship Summary</h3>

      <div class="equation">
        \[ 0 < R_0 < I(X;Y) \leq \log_2(M) \]
      </div>

      <table>
        <tr>
          <th>Quantity</th>
          <th>Symbol</th>
          <th>Meaning</th>
        </tr>
        <tr>
          <td>Error Exponent</td>
          <td>\(E(R)\)</td>
          <td>Rate of error probability decay: \(P_e \approx 2^{-nE(R)}\)</td>
        </tr>
        <tr>
          <td>Cutoff Rate</td>
          <td>\(R_0\)</td>
          <td>Maximum rate for efficient sequential decoding</td>
        </tr>
        <tr>
          <td>Mutual Information</td>
          <td>\(I(X;Y)\)</td>
          <td>Maximum achievable rate (channel capacity)</td>
        </tr>
        <tr>
          <td>Optimal &rho;</td>
          <td>\(\rho^*\)</td>
          <td>Parameter maximizing \(E_0(\rho) - \rho R\)</td>
        </tr>
      </table>
    </section>

    <section id="references">
      <h2>6. References</h2>

      <ol>
        <li>
          <strong>R. G. Gallager</strong>, "A Simple Derivation of the Coding Theorem and Some Applications,"
          <em>IEEE Transactions on Information Theory</em>, vol. 11, no. 1, pp. 3-18, 1965.
        </li>
        <li>
          <strong>R. G. Gallager</strong>, <em>Information Theory and Reliable Communication</em>,
          John Wiley & Sons, 1968.
        </li>
        <li>
          <strong>T. M. Cover and J. A. Thomas</strong>, <em>Elements of Information Theory</em>,
          2nd ed., John Wiley & Sons, 2006.
        </li>
        <li>
          <strong>A. Martinez and A. Guillen i Fabregas</strong>, "Saddlepoint Approximation of Random-Coding Bounds,"
          <em>IEEE Information Theory Workshop</em>, 2009.
        </li>
        <li>
          <strong>G. Kaplan and S. Shamai</strong>, "Information rates and error exponents of compound channels
          with application to antipodal signaling in a fading environment,"
          <em>AEU - International Journal of Electronics and Communications</em>, 1993.
        </li>
      </ol>
    </section>
  </div>

  <footer>
    <p>EPCalculator v2 - Error Probability Calculator for Digital Transmission Systems</p>
    <p>&copy; 2024 - Created for educational and research purposes</p>
  </footer>
</body>
</html>
